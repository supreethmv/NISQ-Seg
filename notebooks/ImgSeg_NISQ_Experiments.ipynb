{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etaCXXCaEX1h"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRE9LAx4s4bi",
        "outputId": "7cb5be99-a71d-41a6-f4f0-e7ca64fb6394"
      },
      "outputs": [],
      "source": [
        "# !pip install qiskit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oGVLr0J783O",
        "outputId": "b2b1be81-e986-4771-e3a6-5c996cbf3f23"
      },
      "outputs": [],
      "source": [
        "# !pip install qiskit_algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wMuyPtOveUd",
        "outputId": "e015ef05-276e-4ccc-a840-ad3b99f99858"
      },
      "outputs": [],
      "source": [
        "# !pip install qiskit_optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ! pip install qiskit-aer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GvybWE1ABIo",
        "outputId": "2633e52d-c4b8-456c-d96f-37418df25737"
      },
      "outputs": [],
      "source": [
        "# !pip install pylatexenc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tG7tOzJrBPp",
        "outputId": "f890920a-3dd9-46e6-9cd9-489a038c9b68"
      },
      "outputs": [],
      "source": [
        "# !pip install gurobipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX28T4NMrHQY",
        "outputId": "0d583a7f-6b9b-4a62-f36d-cde9c43a48c4"
      },
      "outputs": [],
      "source": [
        "# !pip install deap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdVuL-pRn5Dc"
      },
      "outputs": [],
      "source": [
        "# !python -m pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pz-LxpTkcNBZ"
      },
      "outputs": [],
      "source": [
        "# !pip install dwave-ocean-sdk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPI2YbzMa6En"
      },
      "outputs": [],
      "source": [
        "# !pip install dimod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHHL9uIcxjJL"
      },
      "outputs": [],
      "source": [
        "# !pip install qiskit-aqua"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-cQfU8vw0zP"
      },
      "outputs": [],
      "source": [
        "# !pip install pennylane"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIIH27AZERXD"
      },
      "source": [
        "### Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sU_vbxu6utT7"
      },
      "outputs": [],
      "source": [
        "# useful additional packages\n",
        "\n",
        "# import pennylane as qml\n",
        "\n",
        "from qiskit import QuantumRegister, ClassicalRegister\n",
        "from qiskit.tools.monitor import job_monitor\n",
        "from qiskit.circuit.library import Diagonal\n",
        "from qiskit import QuantumCircuit, Aer, execute\n",
        "from qiskit.quantum_info.operators import Operator\n",
        "from qiskit.quantum_info import Pauli\n",
        "from qiskit.extensions import UnitaryGate\n",
        "from qiskit import BasicAer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import os\n",
        "\n",
        "from qiskit.tools.visualization import plot_histogram\n",
        "from qiskit.circuit.library import TwoLocal\n",
        "from qiskit.circuit import Parameter\n",
        "from qiskit_optimization.applications import Maxcut, Tsp\n",
        "from qiskit_optimization.algorithms import MinimumEigenOptimizer\n",
        "\n",
        "\n",
        "from qiskit.utils import algorithm_globals\n",
        "from qiskit.primitives import Sampler\n",
        "\n",
        "from qiskit.circuit.library import TwoLocal\n",
        "from qiskit.quantum_info import Pauli, Statevector\n",
        "from qiskit.result import QuasiDistribution\n",
        "\n",
        "\n",
        "from scipy.optimize import minimize\n",
        "from itertools import combinations\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lb74KYPdbG7s"
      },
      "outputs": [],
      "source": [
        "# UPDATED MODULES\n",
        "\n",
        "from qiskit_algorithms.minimum_eigensolvers import QAOA, SamplingVQE, NumPyMinimumEigensolver\n",
        "from qiskit_algorithms.optimizers import COBYLA\n",
        "\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "from qiskit.primitives import Estimator\n",
        "\n",
        "from qiskit_algorithms.utils import algorithm_globals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LLhsQQ5rUCe"
      },
      "outputs": [],
      "source": [
        "import gurobipy as gp\n",
        "from gurobipy import GRB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-dJsy5Yn9Tm"
      },
      "outputs": [],
      "source": [
        "from deap import base, creator, tools, algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iDrI306n_yo"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PM72KDim82Z6"
      },
      "outputs": [],
      "source": [
        "import dimod\n",
        "from dwave.system.samplers import DWaveSampler\n",
        "from dwave.system.composites import EmbeddingComposite\n",
        "from dwave.samplers import SimulatedAnnealingSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qstUcHjD16P"
      },
      "source": [
        "### Initialize the graph (problem instance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wK32f6HAAgjD",
        "outputId": "9c4133b3-ea68-4e60-c8d7-32aaebb849fe"
      },
      "outputs": [],
      "source": [
        "# n = 3\n",
        "\n",
        "height,width = 3,3\n",
        "\n",
        "image = np.array([\n",
        "       [0.92,  0.87, 0.39],\n",
        "       [0.93,  0.90, 0.45],\n",
        "       [0.94,  0.45, 0.48]\n",
        "       ])\n",
        "plt.imshow(image, interpolation='nearest', cmap=plt.cm.gray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Given data and parameters\n",
        "height, width = 2, 2\n",
        "image = np.array([\n",
        "    [0.92, 0.35],\n",
        "    [0.89, 0.45]\n",
        "])\n",
        "\n",
        "# Plot the image\n",
        "plt.imshow(image, interpolation='nearest', cmap=plt.cm.gray)\n",
        "plt.axis('off')\n",
        "\n",
        "# Annotate each pixel with its position\n",
        "for (i, j), val in np.ndenumerate(image):\n",
        "    plt.text(j, i, f'({i},{j})', ha='center', va='center', color='grey', fontsize=20)\n",
        "\n",
        "# Save the image with annotations\n",
        "plt.savefig(\"2x2_v2.jpg\", dpi=600, bbox_inches='tight', pad_inches=0)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPRFRSJxVqpO",
        "outputId": "29dbb977-864b-4858-d723-433673c47cf3"
      },
      "outputs": [],
      "source": [
        "image.shape, height, width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhDwj6AyA-mW",
        "outputId": "e4bab0c6-c670-4fff-f129-9c266a0c2b97"
      },
      "outputs": [],
      "source": [
        "def image_to_grid_graph(gray_img, sigma=0.5):\n",
        "  # Convert image to grayscale\n",
        "  # gray_img = np.dot(img, [0.2989, 0.5870, 0.1140])\n",
        "  h, w = gray_img.shape\n",
        "  # Initialize graph nodes and edges\n",
        "  nodes = np.zeros((h*w, 1))\n",
        "  edges = []\n",
        "  nx_elist = []\n",
        "  # Compute node potentials and edge weights\n",
        "  min_weight = 1\n",
        "  max_weight = 0\n",
        "  for i in range(h*w):\n",
        "    x, y = i//w, i%w\n",
        "    nodes[i] = gray_img[x,y]\n",
        "    if x > 0:\n",
        "      j = (x-1)*w + y\n",
        "      # weight = np.exp(-dist.euclidean([gray_img[x,y]], [gray_img[x-1,y]])**2 / (2*sigma**2))\n",
        "      weight = np.exp(-((gray_img[x,y] - gray_img[x-1,y])**2) / (2 * sigma**2))\n",
        "      edges.append((i, j, weight))\n",
        "      nx_elist.append(((x,y),(x-1,y),np.round(weight,2)))\n",
        "      if min_weight>weight:min_weight=weight\n",
        "      if max_weight<weight:max_weight=weight\n",
        "    if y > 0:\n",
        "      j = x*w + y-1\n",
        "      # weight = np.exp(-dist.euclidean([gray_img[x,y]], [gray_img[x,y-1]])**2 / (2*sigma**2))\n",
        "      weight = np.exp(-((gray_img[x,y] - gray_img[x,y-1])**2) / (2 * sigma**2))\n",
        "      edges.append((i, j, weight))\n",
        "      nx_elist.append(((x,y),(x,y-1),np.round(weight,2)))\n",
        "      if min_weight>weight:min_weight=weight\n",
        "      if max_weight<weight:max_weight=weight\n",
        "  a=-1\n",
        "  b=1\n",
        "  normalized_edges = [(node1,node2,-1*np.round(((b-a)*((edge_weight-min_weight)/(max_weight-min_weight)))+a,2)) for node1,node2,edge_weight in edges]\n",
        "  normalized_nx_elist = [(node1,node2,-1*np.round(((b-a)*((edge_weight-min_weight)/(max_weight-min_weight)))+a,2)) for node1,node2,edge_weight in nx_elist]\n",
        "  return nodes, edges, nx_elist, normalized_edges, normalized_nx_elist\n",
        "\n",
        "\n",
        "\n",
        "pixel_values, elist, nx_elist, normalized_elist, normalized_nx_elist = image_to_grid_graph(image)\n",
        "\n",
        "pixel_values, elist, nx_elist, normalized_elist, normalized_nx_elist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URDO5nZ7bFwI"
      },
      "outputs": [],
      "source": [
        "G = nx.grid_2d_graph(image.shape[0], image.shape[1])\n",
        "\n",
        "# G.add_weighted_edges_from()\n",
        "G.add_weighted_edges_from(normalized_nx_elist)\n",
        "# G.add_weighted_edges_from(nx_elist)\n",
        "\n",
        "\n",
        "\n",
        "def draw(G):\n",
        "  plt.figure(figsize=(6,6))\n",
        "  default_axes = plt.axes(frameon=True)\n",
        "  pos = {(x,y):(y,-x) for x,y in G.nodes()}\n",
        "  print(\"Pos:\",pos)\n",
        "  nx.draw_networkx(G,\n",
        "                  pos=pos,\n",
        "                  node_color=1-pixel_values,\n",
        "                  with_labels=True,\n",
        "                  node_size=3000,\n",
        "                  cmap=plt.cm.Greys,\n",
        "                  alpha=1,\n",
        "                  ax=default_axes)\n",
        "  nodes = nx.draw_networkx_nodes(G, pos, node_color=1-pixel_values,\n",
        "                  node_size=3000,\n",
        "                  cmap=plt.cm.Greys)\n",
        "  nodes.set_edgecolor('k')\n",
        "  edge_labels = nx.get_edge_attributes(G, \"weight\")\n",
        "  print(edge_labels)\n",
        "  nx.draw_networkx_edge_labels(G,\n",
        "                              pos=pos,\n",
        "                              edge_labels=edge_labels,\n",
        "                              font_size=20)\n",
        "  plt.axis('off')\n",
        "  plt.savefig(\"2x2_graph.jpg\", dpi=600, bbox_inches='tight', pad_inches=0)\n",
        "draw(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RxfJCdPEA7F3",
        "outputId": "de36a835-50ab-4139-cfe4-75de59cca3f1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "def image_to_grid_graph_full(gray_img, sigma=0.5):\n",
        "    h, w = gray_img.shape\n",
        "    nodes = np.zeros((h*w, 1))\n",
        "    normalized_nx_elist = []\n",
        "\n",
        "    # Compute node potentials and edge weights\n",
        "    for i in range(h*w):\n",
        "        x1, y1 = i // w, i % w\n",
        "        nodes[i] = gray_img[x1, y1]\n",
        "        for j in range(i + 1, h * w):\n",
        "            x2, y2 = j // w, j % w\n",
        "            pixel_diff = (gray_img[x1, y1] - gray_img[x2, y2]) ** 2\n",
        "            dist = euclidean((x1, y1), (x2, y2)) ** 2\n",
        "            weight = (1 - np.exp(-pixel_diff / (2 * sigma**2))) / dist\n",
        "            normalized_nx_elist.append(((x1, y1), (x2, y2), np.round(weight, 2)))\n",
        "\n",
        "    return nodes, normalized_nx_elist\n",
        "\n",
        "# Example usage\n",
        "height, width = 3, 3\n",
        "image = np.array([\n",
        "    [0.92, 0.87, 0.39],\n",
        "    [0.93, 0.90, 0.45],\n",
        "    [0.94, 0.45, 0.48]\n",
        "])\n",
        "pixel_values, normalized_nx_elist = image_to_grid_graph_full(image)\n",
        "\n",
        "G = nx.Graph()\n",
        "G.add_nodes_from([(i // width, i % width) for i in range(height * width)])\n",
        "G.add_weighted_edges_from(normalized_nx_elist)\n",
        "\n",
        "# Display the image\n",
        "# plt.imshow(image, interpolation='nearest', cmap=plt.cm.gray)\n",
        "# plt.show()\n",
        "draw(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoHRSsmvPD4y"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oXP6la6icxT"
      },
      "source": [
        "#### Generate Problem Instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsekSYAaBBCX"
      },
      "outputs": [],
      "source": [
        "def image_to_grid_graph(gray_img, sigma=0.5):\n",
        "  # Convert image to grayscale\n",
        "  # gray_img = np.dot(img, [0.2989, 0.5870, 0.1140])\n",
        "  h, w = gray_img.shape\n",
        "  # Initialize graph nodes and edges\n",
        "  nodes = np.zeros((h*w, 1))\n",
        "  edges = []\n",
        "  nx_elist = []\n",
        "  # Compute node potentials and edge weights\n",
        "  min_weight = 1\n",
        "  max_weight = 0\n",
        "  for i in range(h*w):\n",
        "    x, y = i//w, i%w\n",
        "    nodes[i] = gray_img[x,y]\n",
        "    if x > 0:\n",
        "      j = (x-1)*w + y\n",
        "      # weight = np.exp(-dist.euclidean([gray_img[x,y]], [gray_img[x-1,y]])**2 / (2*sigma**2))\n",
        "      weight = 1-np.exp(-((gray_img[x,y] - gray_img[x-1,y])**2) / (2 * sigma**2))\n",
        "      edges.append((i, j, weight))\n",
        "      nx_elist.append(((x,y),(x-1,y),np.round(weight,2)))\n",
        "      if min_weight>weight:min_weight=weight\n",
        "      if max_weight<weight:max_weight=weight\n",
        "    if y > 0:\n",
        "      j = x*w + y-1\n",
        "      # weight = np.exp(-dist.euclidean([gray_img[x,y]], [gray_img[x,y-1]])**2 / (2*sigma**2))\n",
        "      weight = 1-np.exp(-((gray_img[x,y] - gray_img[x,y-1])**2) / (2 * sigma**2))\n",
        "      # print('weight',weight)\n",
        "      edges.append((i, j, weight))\n",
        "      nx_elist.append(((x,y),(x,y-1),np.round(weight,2)))\n",
        "      if min_weight>weight:min_weight=weight\n",
        "      if max_weight<weight:max_weight=weight\n",
        "  a=-1\n",
        "  b=1\n",
        "  if max_weight-min_weight:\n",
        "    normalized_edges = [(node1,node2,-1*np.round(((b-a)*((edge_weight-min_weight)/(max_weight-min_weight)))+a,2)) for node1,node2,edge_weight in edges]\n",
        "    normalized_nx_elist = [(node1,node2,-1*np.round(((b-a)*((edge_weight-min_weight)/(max_weight-min_weight)))+a,2)) for node1,node2,edge_weight in nx_elist]\n",
        "  else:\n",
        "    normalized_edges = [(node1,node2,-1*np.round(edge_weight,2)) for node1,node2,edge_weight in edges]\n",
        "    normalized_nx_elist = [(node1,node2,-1*np.round(edge_weight,2)) for node1,node2,edge_weight in nx_elist]\n",
        "  return nodes, edges, nx_elist, normalized_edges, normalized_nx_elist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Svl8KIOR7NN",
        "outputId": "fea92a28-5551-4bde-fe34-a9cce0b57e27"
      },
      "outputs": [],
      "source": [
        "list1 = [1,1]\n",
        "\n",
        "min_ele = min(list1)\n",
        "max_ele = max(list1)\n",
        "\n",
        "a=-1\n",
        "b=1\n",
        "\n",
        "if max_ele-min_ele:\n",
        "  print([np.round(((b-a)*((ele-min_ele)/(max_ele-min_ele)))+a,2) for ele in list1])\n",
        "else:\n",
        "  print([np.round(ele,2) for ele in list1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQzv7b8hR7KK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ECpvLfdAPkY"
      },
      "outputs": [],
      "source": [
        "def generate_problem_instance(height,width):\n",
        "  image = np.random.rand(height,width)\n",
        "  # plt.imshow(image, interpolation='nearest', cmap=plt.cm.gray)\n",
        "  pixel_values, elist, nx_elist, normalized_elist, normalized_nx_elist = image_to_grid_graph(image)\n",
        "  G = nx.grid_2d_graph(image.shape[0], image.shape[1])\n",
        "  G.add_weighted_edges_from(normalized_nx_elist)\n",
        "  return G, image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTzrHgIF7bcv"
      },
      "outputs": [],
      "source": [
        "def generate_binary_problem_instance(height,width):\n",
        "  image = np.random.rand(height,width)\n",
        "  # print(image)\n",
        "  image[image < 0.5] = 0\n",
        "  image[image >= 0.5] = 1\n",
        "  # print(image)\n",
        "  # plt.imshow(image, interpolation='nearest', cmap=plt.cm.gray)\n",
        "  pixel_values, elist, nx_elist, normalized_elist, normalized_nx_elist = image_to_grid_graph(image)\n",
        "  # print('normalized_elist',normalized_elist)\n",
        "  # print('normalized_nx_elist',normalized_nx_elist\n",
        "  G = nx.grid_2d_graph(image.shape[0], image.shape[1])\n",
        "  G.add_weighted_edges_from(normalized_nx_elist)\n",
        "  return G, image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ofVMOiCgpsit",
        "outputId": "0ab8f8b5-6a3f-4291-8013-a7aa60ec6078"
      },
      "outputs": [],
      "source": [
        "G, image = generate_binary_problem_instance(2,2)\n",
        "print(\"G.number_of_nodes():\",G.number_of_nodes())\n",
        "print(\"nx.adjacency_matrix(G).todense() \\n\",nx.adjacency_matrix(G).todense())\n",
        "plt.imshow(image, interpolation='nearest', cmap=plt.cm.gray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKrRc-FiQNAS",
        "outputId": "41eb49d5-dc73-4789-9bab-71953133b4cb"
      },
      "outputs": [],
      "source": [
        "nx.adjacency_matrix(G).todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3ZeU7SWJeS0"
      },
      "outputs": [],
      "source": [
        "def draw(G, image):\n",
        "  pixel_values = image\n",
        "  plt.figure(figsize=(8,8))\n",
        "  default_axes = plt.axes(frameon=True)\n",
        "  pos = {(x,y):(y,-x) for x,y in G.nodes()}\n",
        "  nx.draw_networkx(G,\n",
        "                  pos=pos,\n",
        "                  node_color=1-pixel_values,\n",
        "                  with_labels=True,\n",
        "                  node_size=3000,\n",
        "                  cmap=plt.cm.Greys,\n",
        "                  alpha=0.8,\n",
        "                  ax=default_axes)\n",
        "  nodes = nx.draw_networkx_nodes(G, pos, node_color=1-pixel_values,\n",
        "                  node_size=3000,\n",
        "                  cmap=plt.cm.Greys)\n",
        "  nodes.set_edgecolor('k')\n",
        "  edge_labels = nx.get_edge_attributes(G, \"weight\")\n",
        "  nx.draw_networkx_edge_labels(G,\n",
        "                              pos=pos,\n",
        "                             edge_labels=edge_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wqP4wGGoN0XO",
        "outputId": "c81bdcd5-c49b-49a7-b3a9-58a579eeefb8"
      },
      "outputs": [],
      "source": [
        "draw(G, image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0sez_uKAJfJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pPiM0ePig7A"
      },
      "source": [
        "#### Brute Force Solver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHWU7Po_FY68"
      },
      "outputs": [],
      "source": [
        "def bf_solver(G):\n",
        "  n = G.number_of_nodes()\n",
        "  w = nx.adjacency_matrix(G).todense()\n",
        "  # print('weights matrix =',w)\n",
        "  best_cost_brute = 100000\n",
        "  for b in range(2**(n-1)):\n",
        "    x = [int(t) for t in reversed(list(bin(b)[2:].zfill(n)))]\n",
        "    cost = 0\n",
        "    for i in range(n):\n",
        "      for j in range(n):\n",
        "        cost = cost + w[i,j]*x[i]*(1-x[j])\n",
        "    if cost < best_cost_brute:\n",
        "      best_cost_brute = cost\n",
        "      xbest_brute = x\n",
        "  return xbest_brute, best_cost_brute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9QBoiilFY4a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXADNms1FY1x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pePrU6XBikMV"
      },
      "source": [
        "#### Minimum Eigen Solver (Classical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upTmCO2gHE3D"
      },
      "outputs": [],
      "source": [
        "def me2_solver(G):\n",
        "  n = G.number_of_nodes()\n",
        "  w = -1 * nx.adjacency_matrix(G).todense()\n",
        "  max_cut = Maxcut(w)\n",
        "  qp = max_cut.to_quadratic_program()\n",
        "  qubitOp, offset = qp.to_ising()\n",
        "  exact = MinimumEigenOptimizer(NumPyMinimumEigensolver())\n",
        "  result = exact.solve(qp)\n",
        "  # return result.x, result.fval\n",
        "  ee = NumPyMinimumEigensolver()\n",
        "  result = ee.compute_minimum_eigenvalue(qubitOp)\n",
        "  x = max_cut.sample_most_likely(result.eigenstate)\n",
        "  return x, qp.objective.evaluate(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFGD5UxzHE0S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAyb7qZ3iqzN"
      },
      "source": [
        "#### Qiskit QAOA Solver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca00hZSt34bH"
      },
      "outputs": [],
      "source": [
        "def objective_value(x: np.ndarray, w: np.ndarray) -> float:\n",
        "    \"\"\"Compute the value of a cut.\n",
        "    Args:\n",
        "        x: Binary string as numpy array.\n",
        "        w: Adjacency matrix.\n",
        "    Returns:\n",
        "        Value of the cut.\n",
        "    \"\"\"\n",
        "    cost = 0\n",
        "    for i in range(len(x)):\n",
        "        for j in range(len(x)):\n",
        "            cost = cost + w[i,j]*x[i]*(1-x[j])\n",
        "    return cost\n",
        "\n",
        "def bitfield(n: int, L: int) -> list[int]:\n",
        "    result = np.binary_repr(n, L)\n",
        "    return [int(digit) for digit in result]  # [2:] to chop off the \"0b\" part\n",
        "\n",
        "def sample_most_likely(state_vector) -> np.ndarray:\n",
        "    \"\"\"Compute the most likely binary string from state vector.\n",
        "    Args:\n",
        "        state_vector: State vector or quasi-distribution.\n",
        "\n",
        "    Returns:\n",
        "        Binary string as an array of ints.\n",
        "    \"\"\"\n",
        "    if isinstance(state_vector, QuasiDistribution):\n",
        "        values = list(state_vector.values())\n",
        "    else:\n",
        "        values = state_vector\n",
        "    n = int(np.log2(len(values)))\n",
        "    k = np.argmax(np.abs(values))\n",
        "    x = bitfield(k, n)\n",
        "    x.reverse()\n",
        "    return np.asarray(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktGfDXARiul4"
      },
      "outputs": [],
      "source": [
        "def qaoa_solver(G, reps=1):\n",
        "  n = G.number_of_nodes()\n",
        "  w = -1 * nx.adjacency_matrix(G).todense()\n",
        "  max_cut = Maxcut(w)\n",
        "  qp = max_cut.to_quadratic_program()\n",
        "  # print(qp.prettyprint())\n",
        "  qubitOp, offset = qp.to_ising()\n",
        "  sampler = Sampler()\n",
        "  algorithm_globals.random_seed = 123\n",
        "  optimizer = COBYLA()\n",
        "  qaoa = QAOA(sampler, optimizer, reps=reps)\n",
        "  result = qaoa.compute_minimum_eigenvalue(qubitOp)\n",
        "  x = sample_most_likely(result.eigenstate)\n",
        "  return x, objective_value(x, w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7JccFLY8tnr"
      },
      "source": [
        "#### Quantum Annealer (D-Wave)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYGraN9emx5X"
      },
      "outputs": [],
      "source": [
        "def dwave_solver(linear, quadratic, offset = 0.0, runs=10000, **kwargs):\n",
        "  \"\"\"\n",
        "  Solve Ising hamiltonian or qubo problem instance using dimod API for using dwave system.\n",
        "  :params\n",
        "  linear: dictionary of linear coefficient terms in the QUBO formulation of the CSG problem.\n",
        "  quadratic: dictionary of quadratic coefficient terms in the QUBO formulation of the CSG problem.\n",
        "  runs: Number of repeated executions\n",
        "  :return\n",
        "  sample_set: Samples and any other data returned by dimod samplers.\n",
        "  \"\"\"\n",
        "  vartype = dimod.BINARY\n",
        "  bqm = dimod.BinaryQuadraticModel(linear, quadratic, 0.0, vartype)\n",
        "  start_time = time.time()\n",
        "  dwave_sampler = DWaveSampler(token = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\", solver={'topology__type': 'pegasus'})\n",
        "  connection_time = time.time() - start_time\n",
        "\n",
        "  start_time = time.time()\n",
        "  sampler = EmbeddingComposite(dwave_sampler)\n",
        "  embedding_time = time.time() - start_time\n",
        "  start_time = time.time()\n",
        "  sample_set = sampler.sample(bqm, num_reads=runs)\n",
        "  response_time = time.time() - start_time\n",
        "  return sample_set, connection_time, embedding_time, response_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFh-LMAzmvsX"
      },
      "outputs": [],
      "source": [
        "def annealer_solver(G, save_log=False, name_folder='distribution', n_samples= 2000, n_run=1, **kwargs):\n",
        "  start_time = time.time()\n",
        "  w = -1 * nx.adjacency_matrix(G).todense()\n",
        "  max_cut = Maxcut(w)\n",
        "  qp = max_cut.to_quadratic_program()\n",
        "  linear = qp.objective.linear.coefficients.toarray(order=None, out=None)\n",
        "  quadratic = qp.objective.quadratic.coefficients.toarray(order=None, out=None)\n",
        "  linear = {int(idx):-round(value,2) for idx,value in enumerate(linear[0])}\n",
        "  quadratic = {(int(iy),int(ix)):-quadratic[iy, ix] for iy, ix in np.ndindex(quadratic.shape) if iy<ix and abs(quadratic[iy, ix])!=0}\n",
        "  problem_formulation_time = time.time() - start_time\n",
        "  sample_set, connection_time, embedding_time, response_time = dwave_solver(linear, quadratic, offset = 0.0, runs=n_samples)\n",
        "  info_dict = sample_set.info['timing'].copy()\n",
        "\n",
        "  start_time = time.time()\n",
        "  samples_df = sample_set.to_pandas_dataframe()\n",
        "  sample_fetch_time = time.time() - start_time\n",
        "\n",
        "  info_dict['problem_formulation_time'] = problem_formulation_time\n",
        "  info_dict['connection_time'] = connection_time\n",
        "  info_dict['embedding_time'] = embedding_time\n",
        "  info_dict['response_time'] = response_time\n",
        "  info_dict['sample_fetch_time'] = sample_fetch_time\n",
        "  return samples_df, info_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LNWfV9V9FAA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNJMb9PMiu1S"
      },
      "source": [
        "#### New NISQ Solver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2cShEH_F_NP"
      },
      "outputs": [],
      "source": [
        "def R(theta):\n",
        "  if abs(theta) > 2*np.pi or abs(theta) < 0:\n",
        "    theta = abs(theta) - (np.floor(abs(theta)/(2*np.pi))*(2*np.pi))\n",
        "  return 0 if 0 <= theta < np.pi else 1\n",
        "\n",
        "def cost_fn(params, hermitian_observable):\n",
        "  global optimization_iteration_count\n",
        "  optimization_iteration_count += 1\n",
        "  N = int(np.log2(len(params)))\n",
        "  circuit_psi = QuantumCircuit(N)\n",
        "  for i in range(N):\n",
        "    circuit_psi.h(i)\n",
        "  diagonal_elements = [np.exp(1j * np.pi * R(param)) for param in params]\n",
        "  diag_gate = Diagonal(diagonal_elements)\n",
        "  circuit_psi.append(diag_gate, range(N))\n",
        "  op_observable = SparsePauliOp.from_operator(hermitian_observable)\n",
        "  cost = Estimator().run(circuit_psi, op_observable).result().values[0]\n",
        "  print(f'@ Iteration {optimization_iteration_count} Cost :',cost)\n",
        "  return cost\n",
        "\n",
        "def decode(optimal_params):\n",
        "  return [R(param) for param in optimal_params]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRYhybg31Xkf"
      },
      "outputs": [],
      "source": [
        "def new_nisq_ga_solver2(G, population_size=50, crossover_probability=0.7, mutation_probability=0.2, number_of_generations=50):\n",
        "    n = G.number_of_nodes()\n",
        "    w = nx.adjacency_matrix(G).todense()\n",
        "    D_G = np.diag(list(dict(G.degree()).values()))\n",
        "    A_G = w\n",
        "    L_G = D_G - A_G\n",
        "    n_padding = (2**int(np.ceil(np.log2(n))) - n)\n",
        "    L_G = np.pad(L_G, [(0, n_padding), (0, n_padding)], mode='constant')\n",
        "    H = L_G\n",
        "\n",
        "    # Genetic Algorithm Setup\n",
        "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
        "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
        "\n",
        "    toolbox = base.Toolbox()\n",
        "    toolbox.register(\"attr_float\", random.uniform, 0.5, 2*np.pi)\n",
        "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, n)\n",
        "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "    # Evaluate function with padding\n",
        "    def evaluate_with_padding(individual):\n",
        "        padded_individual = individual + [0] * n_padding  # Append constant values for padding\n",
        "        return cost_fn(padded_individual, H),\n",
        "\n",
        "    toolbox.register(\"evaluate\", evaluate_with_padding)\n",
        "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "    toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.1)\n",
        "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "    # Run Genetic Algorithm\n",
        "    population = toolbox.population(n=population_size)\n",
        "    algorithms.eaSimple(population, toolbox, cxpb=crossover_probability, mutpb=mutation_probability, ngen=number_of_generations, verbose=False)\n",
        "\n",
        "    # Extract the best solution\n",
        "    best_ind = tools.selBest(population, 1)[0]\n",
        "    optimal_params = best_ind + [0] * n_padding  # Append constant values for padding\n",
        "    expectation_value = best_ind.fitness.values[0]\n",
        "\n",
        "    # Decode and calculate cut value\n",
        "    x = np.real(decode(optimal_params))\n",
        "    x = x[:n]\n",
        "    cut_value = objective_value(x, w)\n",
        "\n",
        "    return x, expectation_value, cut_value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQ7-zs4s3ec9"
      },
      "outputs": [],
      "source": [
        "def new_nisq_algo_solver(G, optimizer_method = 'Genetic', initial_params_seed=123):\n",
        "  global optimization_iteration_count\n",
        "  optimization_iteration_count = 0\n",
        "  if optimizer_method == 'Genetic':\n",
        "    x, expectation_value, cut_value = new_nisq_ga_solver2(G,\n",
        "                                                         population_size = 50,\n",
        "                                                         crossover_probability = 0.7,\n",
        "                                                         mutation_probability = 0.2,\n",
        "                                                         number_of_generations = 50)\n",
        "    success_flag = True\n",
        "  else:\n",
        "    n = G.number_of_nodes()\n",
        "    w = nx.adjacency_matrix(G).todense()\n",
        "    D_G = np.diag(list(dict(G.degree()).values()))\n",
        "    A_G = w\n",
        "    L_G = D_G - A_G\n",
        "    n_padding = (2**int(np.ceil(np.log2(n)))-n)\n",
        "    L_G = np.pad(L_G, [(0, n_padding), (0, n_padding) ], mode='constant')\n",
        "    H = L_G\n",
        "    # if initial_params is None:\n",
        "    np.random.seed(seed=initial_params_seed)\n",
        "    initial_params = np.random.uniform(low=0.5, high=2*np.pi , size=(n+n_padding))\n",
        "    # optimizers_scipy = ['Nelder-Mead', 'Powell', 'CG', 'BFGS', 'L-BFGS-B', 'TNC', 'COBYLA', 'SLSQP']\n",
        "    # print(optimizer_method)\n",
        "    options = {}\n",
        "    result = minimize(\n",
        "        fun=cost_fn,\n",
        "        x0=initial_params,  # Initial guess for the parameters\n",
        "        args=H,    # Additional arguments passed to evaluate_cost\n",
        "        method=optimizer_method,\n",
        "        options=options)\n",
        "    \n",
        "    optimal_params, expectation_value = result.x, result.fun\n",
        "    x = np.real(decode(optimal_params))\n",
        "    x = x[:n]\n",
        "    cut_value = objective_value(x, w)\n",
        "    success_flag = result.success\n",
        "  return success_flag, x, expectation_value, cut_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Experiments for New NISQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocUzdcG3MlLx"
      },
      "outputs": [],
      "source": [
        "# max_layers = 20\n",
        "# n_shots = 65536\n",
        "\n",
        "# optimization_max_iter = 10000\n",
        "\n",
        "\n",
        "# heights = np.arange(2, 17).tolist()\n",
        "heights = [2,4,8,16]\n",
        "heights = [16]\n",
        "\n",
        "# scipy_optimizer_methods = [\"COBYLA\", \"Nelder-Mead\", \"Powell\", \"CG\", \"BFGS\", \"Newton-CG\", \"L-BFGS-B\", \"SLSQP\", \"trust-const\", \"dogleg\", \"trust-ncg\", \"trust-exact\", \"trust-krylov\"]\n",
        "# scipy_optimizer_methods = [\"COBYLA\", \"Nelder-Mead\", \"Powell\", \"CG\", \"BFGS\", \"L-BFGS-B\", \"SLSQP\"]\n",
        "# scipy_optimizer_methods = [\"COBYLA\", \"Powell\", \"CG\", \"BFGS\", \"L-BFGS-B\", \"SLSQP\"]\n",
        "scipy_optimizer_methods = [\"COBYLA\"]\n",
        "# optimizer_method = 'Powell'\n",
        "\n",
        "seed = 111\n",
        "initial_params_seed = 123\n",
        "\n",
        "ultimate_valid_probabilities = []\n",
        "penultimate_valid_probabilities = []\n",
        "optimization_iteration_count = 0\n",
        "\n",
        "base_path = './'\n",
        "report_filename = base_path + 'NewNISQv2_' +  str(seed) + '_.txt'\n",
        "# report_filename = base_path + 'SampleTestMinimalEncoding_' +  str(seed) + '_' + str(n_shots) + '.txt'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "report_filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "for height in heights:\n",
        "  width = height\n",
        "  print(f'height: {height}, width: {width}, n: {height*width}')\n",
        "  # G, image = generate_binary_problem_instance(height, width)\n",
        "  np.random.seed(seed=seed)\n",
        "  G, image = generate_problem_instance(height, width)\n",
        "  G, image = generate_binary_problem_instance(height, width)\n",
        "  print(\"Image Generated: \",image)\n",
        "  # plt.imshow(image, cmap=plt.cm.gray)\n",
        "  # plt.show()\n",
        "\n",
        "  for optimizer_method in scipy_optimizer_methods:\n",
        "    # if G.number_of_nodes() <= max_layers:\n",
        "      # max_layers = G.number_of_nodes()\n",
        "    # else:\n",
        "      # max_layers = 30\n",
        "    # print(\"Maximum number of layers :\", max_layers)\n",
        "    # for n_layers in range(1, 1+1,1):\n",
        "    #   nc = len(G.nodes())\n",
        "    #   nr = ceil(log2(nc))\n",
        "    #   nq = nr + 1\n",
        "      # np.random.seed(seed=initial_params_seed)\n",
        "      # initial_params = np.random.uniform(low=-np.pi, high=np.pi, size=nq*n_layers)\n",
        "    print(f\"Executing QC with {optimizer_method} optimizer for {height}*{height} image.\")\n",
        "    # try:\n",
        "    start_time = time.time()\n",
        "      # success_flag, minimal_encoding_solution, minimal_encoding_value, minimal_encoding_cut_value, optimal_params = minimal_encoding(G, \n",
        "                                                                                                                    # initial_params, \n",
        "                                                                                                                    # n_layers = n_layers,\n",
        "                                                                                                                    # max_iter = optimization_max_iter,\n",
        "                                                                                                                    # optimizer_method = scipy_optimizer_method)\n",
        "    success_flag, new_nisq_solution, new_nisq_expectation_value, new_nisq_cut_value = new_nisq_algo_solver(G, optimizer_method = optimizer_method, initial_params_seed=initial_params_seed)\n",
        "    new_nisq_tte = (time.time() - start_time)\n",
        "    print(new_nisq_solution, new_nisq_expectation_value, new_nisq_cut_value)\n",
        "    # except:\n",
        "      # print(f\"Execution Failed for {n_layers} layers and {scipy_optimizer_method} optimizer for {height}*{height} image.\")\n",
        "      # continue\n",
        "    # print(\"New NISQ done for\",scipy_optimizer_method,\"optimizer with a success status :\", success_flag)\n",
        "    # print(f\"Appending the results of {height}*{height} image using QC with {n_layers} layers and {scipy_optimizer_method} optimizer.\")\n",
        "    row = []\n",
        "    row.append(int(G.number_of_nodes()))\n",
        "    row.append(int(height))\n",
        "    row.append(int(width))\n",
        "    row.append(success_flag)\n",
        "    row.append(''.join(map(str, map(int, (new_nisq_solution)))))\n",
        "    row.append(np.round(new_nisq_tte,6))\n",
        "    row.append(np.round(new_nisq_cut_value,4))\n",
        "    row.append(np.round(new_nisq_expectation_value,4))\n",
        "    row.append(optimization_iteration_count)\n",
        "    row.append(optimizer_method)\n",
        "    # row.append(''.join(map(str, map(float, (optimal_params)))))\n",
        "    report_file_obj = open(os.path.join(report_filename),'a+')\n",
        "    report_file_obj.write('__'.join(map(str,row))+'\\n')\n",
        "    report_file_obj.close()\n",
        "    # plt.imshow(decode_binary_string(minimal_encoding_solution, height,height), cmap=plt.cm.gray)\n",
        "    # plt.show()\n",
        "    # if success_flag:\n",
        "      # break\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def truncate_long_string(s, max_length=20):\n",
        "    return s if len(s) <= max_length else s[:max_length] + \"...\"\n",
        "\n",
        "def style_df(df):\n",
        "    # Styles for hover and headers\n",
        "    cell_hover = {'selector': 'tr:hover', 'props': [('background-color', '#707070')]}  # Dark pale color for hover\n",
        "    headers = {'selector': 'th', 'props': 'background-color: #1D1D1D; color: white;'}\n",
        "\n",
        "    # Column separator style\n",
        "    column_separator = {'selector': 'td, th', 'props': 'border-right: 1px solid white;'}\n",
        "\n",
        "    # Apply the styles\n",
        "    styled_df = df.style.set_table_styles([cell_hover, headers, column_separator])\n",
        "\n",
        "    # Style to hide the border for the last column to prevent a double line at the end of the table\n",
        "    hide_last_border = {'selector': 'td:last-child, th:last-child', 'props': 'border-right: none;'}\n",
        "\n",
        "    # Combine all styles\n",
        "    styles = [cell_hover, headers, column_separator, hide_last_border]\n",
        "    styled_df = styled_df.set_table_styles(styles, overwrite=False)\n",
        "\n",
        "    return styled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_path = './'\n",
        "report_filename = base_path + 'minimalEncoding_' +  str(seed) + '_' + str(16384) + '.txt'\n",
        "# report_filename = base_path + 'minimalEncoding_' +  str(seed) + '_' + str(32768) + '.txt'\n",
        "# report_filename = base_path + 'SampleTestMinimalEncoding_' +  str(seed) + '_' + str(8192) + '.txt'\n",
        "report_file_obj = open(report_filename,'r')\n",
        "table_contents = [line.replace('\\n','').split('__') for line in report_file_obj.readlines()]\n",
        "\n",
        "base_cols = ['No. of Pixels', 'Height', 'Width']\n",
        "sub_cols = ['','','']\n",
        "\n",
        "extra_sub_cols = ['Optimization Success','Result', 'TTE', 'Layers', 'Min-Cut Cost', 'Optimization Cost', 'Iterations', 'Optimizer Method']\n",
        "base_cols = base_cols+['Minimal Encoding Solver']*len(extra_sub_cols)\n",
        "sub_cols=sub_cols+extra_sub_cols\n",
        "\n",
        "column_arrays = [base_cols, sub_cols]\n",
        "\n",
        "#df = pd.DataFrame(table_contents, columns=table_headers)\n",
        "df = pd.DataFrame(table_contents, columns=pd.MultiIndex.from_arrays(column_arrays))\n",
        "\n",
        "for col in df.columns:\n",
        "  if len(col) == 2 and col[1] == 'Result':\n",
        "    df[col] = df[col].apply(lambda x: truncate_long_string(x))\n",
        "\n",
        "styled_df = style_df(df)#.apply(highlight_row, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "styled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTxQ4fTDMpT_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gn9LlESO-aD3"
      },
      "outputs": [],
      "source": [
        "# G, image = generate_binary_problem_instance(2,2)\n",
        "# plt.imshow(image, cmap=plt.cm.gray)\n",
        "# draw(G, image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5-M5oQd_IOU"
      },
      "outputs": [],
      "source": [
        "# # scipy_optimizer_method = \"Powell\"\n",
        "\n",
        "# height = 4\n",
        "\n",
        "# seed = 111\n",
        "# np.random.seed(seed=seed)\n",
        "# G, image = generate_binary_problem_instance(height, height)\n",
        "\n",
        "# start = time.time()\n",
        "# new_nisq_solution, new_nisq_expectation_value, new_nisq_cut_value = new_nisq_ga_solver(G, population_size = min(10,int(2*G.number_of_nodes())),\n",
        "#                                                                                        crossover_probability = 0.5,\n",
        "#                                                                                        mutation_probability = 0.5,\n",
        "#                                                                                        number_of_generations = min(10,int(2*G.number_of_nodes())))\n",
        "# new_nisq_solution, new_nisq_expectation_value, new_nisq_cut_value, time.time()-start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlDR7Sbs-8BB"
      },
      "outputs": [],
      "source": [
        "# start = time.time()\n",
        "# new_nisq_solution, new_nisq_expectation_value, new_nisq_cut_value = new_nisq_ga_solver2(G, population_size = min(10,int(2*G.number_of_nodes())),\n",
        "#                                                                                         crossover_probability = 0.5,\n",
        "#                                                                                         mutation_probability = 0.5,\n",
        "#                                                                                         number_of_generations = min(10,int(2*G.number_of_nodes())))\n",
        "# new_nisq_solution, new_nisq_expectation_value, new_nisq_cut_value, time.time()-start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUWHhFRg-7-R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4gYm6GG-Z-V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqDbe7zClcdo"
      },
      "source": [
        "#### Minimal Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSzfRUk7wGil"
      },
      "outputs": [],
      "source": [
        "from qiskit import Aer, execute\n",
        "from qiskit.visualization import plot_histogram\n",
        "from qiskit.quantum_info import Statevector\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ND2Ty507VpP"
      },
      "outputs": [],
      "source": [
        "from qiskit.circuit import ParameterVector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL7RlivtrNpu"
      },
      "outputs": [],
      "source": [
        "from qiskit import QuantumCircuit\n",
        "from math import log2, ceil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_circuit(nq, n_layers):\n",
        "  theta = ParameterVector('', length=nq*n_layers)\n",
        "  qc = QuantumCircuit(nq)\n",
        "  qc.h(range(nq))\n",
        "\n",
        "  for layer_i in range(n_layers):\n",
        "    if layer_i%2:\n",
        "      for qubit_i in range(nq - 1):\n",
        "        qc.cx(qubit_i, (qubit_i + 1)%nq)\n",
        "    for qubit_i in range(nq):\n",
        "      qc.ry(theta[(nq*layer_i)+qubit_i], qubit_i)\n",
        "  return qc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfjhMWsyljcp"
      },
      "outputs": [],
      "source": [
        "# def measure_probabilities(qc, nq, backend=Aer.get_backend('qasm_simulator')):\n",
        "#   qc.measure_all()\n",
        "#   job = execute(qc, backend, shots=1024)\n",
        "#   result = job.result()\n",
        "#   counts = result.get_counts(qc)\n",
        "#   probabilities = {state: count / 1024 for state, count in counts.items()}\n",
        "#   return probabilities\n",
        "\n",
        "def get_projectors(probabilities, n_c):\n",
        "  P = [0] * n_c\n",
        "  P1 = [0] * n_c\n",
        "  for k, v in probabilities.items():\n",
        "    index = int(k[1:], 2)\n",
        "    P[index] += v\n",
        "    if k[0] == '1':\n",
        "      P1[index] += v\n",
        "  return P, P1\n",
        "\n",
        "def evaluate_cost(params, circuit, qubo_matrix):\n",
        "  global ultimate_valid_probabilities\n",
        "  global penultimate_valid_probabilities\n",
        "  global optimization_iteration_count\n",
        "  global n_shots\n",
        "  optimization_iteration_count += 1\n",
        "  # Create a copy of the circuit to avoid modifying the original\n",
        "  working_circuit = circuit.copy()\n",
        "\n",
        "  # Apply measurements\n",
        "  working_circuit.measure_all()\n",
        "\n",
        "  # Bind the parameters to the circuit\n",
        "  bound_circuit = working_circuit.assign_parameters(params)\n",
        "\n",
        "  # Run the circuit on a simulator\n",
        "\n",
        "  # n_shots = 8192\n",
        "  # n_shots = 16384\n",
        "  # n_shots = 32768\n",
        "  simulator = Aer.get_backend('qasm_simulator')\n",
        "  job = execute(bound_circuit, simulator, shots=n_shots)\n",
        "  result = job.result()\n",
        "  counts = result.get_counts()\n",
        "\n",
        "  # Compute the probabilities of the states\n",
        "  probabilities = {state: counts[state] / n_shots for state in counts}\n",
        "  # print('probabilities',probabilities)\n",
        "  # print('ultimate_valid_probabilities',ultimate_valid_probabilities)\n",
        "  # print('penultimate_valid_probabilities',penultimate_valid_probabilities)\n",
        "  n_c = 2**(len(list(probabilities.keys())[0])-1)\n",
        "  # n_c = qubo.shape[0]\n",
        "  P, P1 = get_projectors(probabilities, n_c)\n",
        "\n",
        "  if 0 in P:\n",
        "    return 100000\n",
        "  else:\n",
        "    # Update the last valid probabilities\n",
        "    penultimate_valid_probabilities = ultimate_valid_probabilities.copy()\n",
        "    ultimate_valid_probabilities = probabilities.copy()\n",
        "\n",
        "  cost = 0\n",
        "  for i in range(len(qubo_matrix)):\n",
        "    for j in range(len(qubo_matrix)):\n",
        "      if i==j:\n",
        "        cost += qubo_matrix[i][j] * P1[i]/P[i]\n",
        "      else:\n",
        "        cost += (qubo_matrix[i][j]*P1[i]*P1[j])/(P[i]*P[j])\n",
        "  # binary_string = decode_probabilities(probabilities)\n",
        "  # print('Binary String :', binary_string)\n",
        "  # min_cut_cost = 0\n",
        "  # for i in range(len(binary_string)):\n",
        "    # for j in range(len(binary_string)):\n",
        "      # min_cut_cost = min_cut_cost + qubo_matrix[i][j]*binary_string[i]*(1-binary_string[j])\n",
        "  # print('min_cut_cost :', min_cut_cost)\n",
        "  print(f'@ Iteration {optimization_iteration_count} Cost :',cost)\n",
        "  return cost\n",
        "\n",
        "def get_final_measurement_binary_string(circuit, params):\n",
        "  # Create a copy of the circuit to avoid modifying the original\n",
        "  working_circuit = circuit.copy()\n",
        "  # Apply measurements\n",
        "  working_circuit.measure_all()\n",
        "  # Bind the parameters to the circuit\n",
        "  bound_circuit = working_circuit.assign_parameters(params)\n",
        "  # Run the circuit on a simulator\n",
        "  simulator = Aer.get_backend('qasm_simulator')\n",
        "  job = execute(bound_circuit, simulator, shots=1024)\n",
        "  result = job.result()\n",
        "  counts = result.get_counts()\n",
        "  # Compute the probabilities of the states\n",
        "  probabilities = {state: counts[state] / 1024 for state in counts}\n",
        "  return probabilities\n",
        "\n",
        "def decode_probabilities(probabilities):\n",
        "  binary_solution = []\n",
        "  n_r = len(list(probabilities.keys())[0])-1\n",
        "  n_c = 2**(n_r)\n",
        "  for i in range(n_c):\n",
        "    if '0' + format(i, 'b').zfill(n_r) in probabilities and '1' + format(i, 'b').zfill(n_r) in probabilities:\n",
        "      if probabilities['0' + format(i, 'b').zfill(n_r)] > probabilities['1' + format(i, 'b').zfill(n_r)]:\n",
        "        binary_solution.append(0)\n",
        "      else:\n",
        "        binary_solution.append(1)\n",
        "    elif '0' + format(i, 'b').zfill(n_r) in probabilities:\n",
        "      binary_solution.append(0)\n",
        "    elif '1' + format(i, 'b').zfill(n_r) in probabilities:\n",
        "      binary_solution.append(1)\n",
        "  return binary_solution\n",
        "\n",
        "def decode_binary_string(x, height, width):\n",
        "  mask = np.zeros([height, width])\n",
        "  for index,segment in enumerate(x):\n",
        "    mask[index//width,index%width]=segment\n",
        "  return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# For a larger number of shots, rather than measuring the probabilities, use statevector simulator, we get the statevectors itself instead of proababilities, squaring the amplitudes we get probabilities.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXTiq8k1dvjp"
      },
      "outputs": [],
      "source": [
        "# x_1 = 'state of the ancilla qubit whose register qubits are in the state (00) with high probability' = 1\n",
        "# x_2 = 'state of the ancilla qubit whose register qubits are in the state (01) with high probability' = 1\n",
        "# x_3 = 'state of the ancilla qubit whose register qubits are in the state (10) with high probability' = 0\n",
        "# x_4 = 'state of the ancilla qubit whose register qubits are in the state (11) with high probability' = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFdTy6FvljZv"
      },
      "outputs": [],
      "source": [
        "def minimal_encoding(G, initial_params, n_layers = 1, max_iter = 2000, optimizer_method = 'COBYLA'):\n",
        "\n",
        "  w = nx.adjacency_matrix(G).todense()\n",
        "  max_cut = Maxcut(-w)\n",
        "  qp = max_cut.to_quadratic_program()\n",
        "  linear = qp.objective.linear.coefficients.toarray(order=None, out=None)\n",
        "  quadratic = qp.objective.quadratic.coefficients.toarray(order=None, out=None)\n",
        "  linear = {int(idx):-round(value,2) for idx,value in enumerate(linear[0])}\n",
        "  quadratic = {(int(iy),int(ix)):-quadratic[iy, ix] for iy, ix in np.ndindex(quadratic.shape) if iy<ix and abs(quadratic[iy, ix])!=0}\n",
        "  nc = len(linear)\n",
        "  nr = ceil(log2(nc))\n",
        "  nq = nr + 1\n",
        "  qubo = np.zeros((nc, nc))\n",
        "  np.fill_diagonal(qubo, list(linear.values()))\n",
        "  for (i, j), value in quadratic.items():\n",
        "    qubo[i, j] = qubo[j, i] = value\n",
        "  qc = get_circuit(nq, n_layers)\n",
        "  # initial_params = np.random.uniform(low=-np.pi, high=np.pi, size=nq*n_layers)\n",
        "  global ultimate_valid_probabilities\n",
        "  global penultimate_valid_probabilities\n",
        "  global optimization_iteration_count\n",
        "  ultimate_valid_probabilities = []\n",
        "  penultimate_valid_probabilities = []\n",
        "  optimization_iteration_count = 0\n",
        "  \n",
        "  # Correct way to call the minimize function\n",
        "  options = {'maxiter': max_iter, 'rhoend':1e-8, 'maxfun':max_iter, 'disp':None, 'catol':2e-8}\n",
        "  optimization_result = minimize(\n",
        "      fun=evaluate_cost,\n",
        "      x0=initial_params,  # Initial guess for the parameters\n",
        "      args=(qc, qubo),    # Additional arguments passed to evaluate_cost\n",
        "      method=optimizer_method,\n",
        "      options=options)\n",
        "  if not len(ultimate_valid_probabilities):\n",
        "    return False, [0]*nc, 0, 0, [0]*initial_params\n",
        "  binary_string_solution = decode_probabilities(ultimate_valid_probabilities)\n",
        "  minimization_cost = optimization_result.fun\n",
        "  optimal_params = optimization_result.x\n",
        "  cut_cost = 0\n",
        "  cut_cost = objective_value(np.array(list(map(int,binary_string_solution))), w)\n",
        "  # print(\"W.shape :\",w.shape)\n",
        "  # print(\"len(binary_string_solution) :\",len(binary_string_solution))\n",
        "  # for i in range(len(binary_string_solution)):\n",
        "    # for j in range(len(binary_string_solution)):\n",
        "      # cut_cost = cut_cost + w[i,j]*binary_string_solution[i]*(1-binary_string_solution[j])\n",
        "  return optimization_result.success, binary_string_solution, minimization_cost, cut_cost, optimal_params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def truncate_long_string(s, max_length=20):\n",
        "    return s if len(s) <= max_length else s[:max_length] + \"...\"\n",
        "\n",
        "\n",
        "def style_df(df):\n",
        "    # Styles for hover and headers\n",
        "    cell_hover = {'selector': 'tr:hover', 'props': [('background-color', '#707070')]}  # Dark pale color for hover\n",
        "    headers = {'selector': 'th', 'props': 'background-color: #1D1D1D; color: white;'}\n",
        "\n",
        "    # Column separator style\n",
        "    column_separator = {'selector': 'td, th', 'props': 'border-right: 1px solid white;'}\n",
        "\n",
        "    # Apply the styles\n",
        "    styled_df = df.style.set_table_styles([cell_hover, headers, column_separator])\n",
        "\n",
        "    # Style to hide the border for the last column to prevent a double line at the end of the table\n",
        "    hide_last_border = {'selector': 'td:last-child, th:last-child', 'props': 'border-right: none;'}\n",
        "\n",
        "    # Combine all styles\n",
        "    styles = [cell_hover, headers, column_separator, hide_last_border]\n",
        "    styled_df = styled_df.set_table_styles(styles, overwrite=False)\n",
        "\n",
        "    return styled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Experiments for Minimal Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_layers = 20\n",
        "n_shots = 65536\n",
        "\n",
        "optimization_max_iter = 10000\n",
        "\n",
        "\n",
        "# heights = np.arange(2, 17).tolist()\n",
        "heights = [2,4,8,16]\n",
        "heights = [2,4,8]\n",
        "# heights = [8]\n",
        "\n",
        "# scipy_optimizer_methods = [\"COBYLA\", \"Nelder-Mead\", \"Powell\", \"CG\", \"BFGS\", \"Newton-CG\", \"L-BFGS-B\", \"SLSQP\", \"trust-const\", \"dogleg\", \"trust-ncg\", \"trust-exact\", \"trust-krylov\"]\n",
        "# scipy_optimizer_methods = [\"COBYLA\", \"Nelder-Mead\", \"Powell\", \"CG\", \"BFGS\", \"L-BFGS-B\", \"SLSQP\"]\n",
        "# scipy_optimizer_methods = [\"COBYLA\", \"Powell\", \"CG\", \"BFGS\", \"L-BFGS-B\", \"SLSQP\"]\n",
        "scipy_optimizer_methods = [\"COBYLA\"]\n",
        "# scipy_optimizer_methods = [\"COBYLA\", \"CG\", \"BFGS\", \"L-BFGS-B\", \"SLSQP\"]\n",
        "# scipy_optimizer_methods = [\"Genetic\"]\n",
        "\n",
        "\n",
        "seed = 222\n",
        "initial_params_seed = 123\n",
        "\n",
        "ultimate_valid_probabilities = []\n",
        "penultimate_valid_probabilities = []\n",
        "optimization_iteration_count = 0\n",
        "\n",
        "base_path = './'\n",
        "report_filename = base_path + 'minimalEncoding_' +  str(seed) + '_' + str(n_shots) + '.txt'\n",
        "# report_filename = base_path + 'SampleTestMinimalEncoding_' +  str(seed) + '_' + str(n_shots) + '.txt'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "report_filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# height = 2\n",
        "# width = height\n",
        "# np.random.seed(seed=seed)\n",
        "# G, image = generate_problem_instance(height, width)\n",
        "# w = nx.adjacency_matrix(G).todense()\n",
        "# w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# gurobi_solution, gurobi_value = gurobi_mincut_solver(G)\n",
        "\n",
        "# print(''.join(map(str, map(int, (gurobi_solution)))))\n",
        "# print(gurobi_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seeds = [222,333,444,555]\n",
        "seeds = [222]\n",
        "seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC2NqX3krgP5"
      },
      "outputs": [],
      "source": [
        "for seed in seeds:\n",
        "  base_path = './'\n",
        "  report_filename = base_path + 'minimalEncodingv3_' +  str(seed) + '_' + str(n_shots) + '.txt'\n",
        "  for height in heights:\n",
        "    width = height\n",
        "    print(f'height: {height}, width: {width}, n: {height*width}')\n",
        "    # G, image = generate_binary_problem_instance(height, width)\n",
        "    np.random.seed(seed=seed)\n",
        "    G, image = generate_problem_instance(height, width)\n",
        "    print(\"Image Generated: \",image)\n",
        "    # plt.imshow(image, cmap=plt.cm.gray)\n",
        "    # plt.show()\n",
        "\n",
        "    for scipy_optimizer_method in scipy_optimizer_methods:\n",
        "      # if G.number_of_nodes() <= max_layers:\n",
        "        # max_layers = G.number_of_nodes()\n",
        "      # else:\n",
        "        # max_layers = 30\n",
        "      print(\"Maximum number of layers :\", max_layers)\n",
        "      for n_layers in range(6, max_layers+1,1):\n",
        "        nc = len(G.nodes())\n",
        "        nr = ceil(log2(nc))\n",
        "        nq = nr + 1\n",
        "        np.random.seed(seed=initial_params_seed)\n",
        "        initial_params = np.random.uniform(low=-np.pi, high=np.pi, size=nq*n_layers)\n",
        "        print(f\"Executing QC with {n_layers} layers and {scipy_optimizer_method} optimizer for {height}*{height} image.\")\n",
        "        try:\n",
        "          start_time = time.time()\n",
        "          success_flag, minimal_encoding_solution, minimal_encoding_value, minimal_encoding_cut_value, optimal_params = minimal_encoding(G,\n",
        "                                                                                                                        initial_params,\n",
        "                                                                                                                        n_layers = n_layers,\n",
        "                                                                                                                        max_iter = optimization_max_iter,\n",
        "                                                                                                                        optimizer_method = scipy_optimizer_method)\n",
        "          minimal_encoding_tte = (time.time() - start_time)\n",
        "        except:\n",
        "          print(f\"Execution Failed for {n_layers} layers and {scipy_optimizer_method} optimizer for {height}*{height} image.\")\n",
        "          continue\n",
        "        print(\"New NISQ done for\",scipy_optimizer_method,\"optimizer with a success status :\", success_flag)\n",
        "        print(f\"Appending the results of {height}*{height} image using QC with {n_layers} layers and {scipy_optimizer_method} optimizer.\")\n",
        "        row = []\n",
        "        row.append(int(G.number_of_nodes()))\n",
        "        row.append(int(height))\n",
        "        row.append(int(width))\n",
        "        row.append(success_flag)\n",
        "        row.append(''.join(map(str, map(int, (minimal_encoding_solution)))))\n",
        "        row.append(np.round(minimal_encoding_tte,6))\n",
        "        row.append(n_layers)\n",
        "        row.append(np.round(minimal_encoding_cut_value,4))\n",
        "        row.append(np.round(minimal_encoding_value,4))\n",
        "        row.append(optimization_iteration_count)\n",
        "        row.append(scipy_optimizer_method)\n",
        "        # row.append(''.join(map(str, map(float, (optimal_params)))))\n",
        "        report_file_obj = open(os.path.join(report_filename),'a+')\n",
        "        report_file_obj.write('__'.join(map(str,row))+'\\n')\n",
        "        report_file_obj.close()\n",
        "        # plt.imshow(decode_binary_string(minimal_encoding_solution, height,height), cmap=plt.cm.gray)\n",
        "        # plt.show()\n",
        "        # if success_flag:\n",
        "          # break\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def truncate_long_string(s, max_length=20):\n",
        "    return s if len(s) <= max_length else s[:max_length] + \"...\"\n",
        "\n",
        "def style_df(df):\n",
        "    # Styles for hover and headers\n",
        "    cell_hover = {'selector': 'tr:hover', 'props': [('background-color', '#707070')]}  # Dark pale color for hover\n",
        "    headers = {'selector': 'th', 'props': 'background-color: #1D1D1D; color: white;'}\n",
        "\n",
        "    # Column separator style\n",
        "    column_separator = {'selector': 'td, th', 'props': 'border-right: 1px solid white;'}\n",
        "\n",
        "    # Apply the styles\n",
        "    styled_df = df.style.set_table_styles([cell_hover, headers, column_separator])\n",
        "\n",
        "    # Style to hide the border for the last column to prevent a double line at the end of the table\n",
        "    hide_last_border = {'selector': 'td:last-child, th:last-child', 'props': 'border-right: none;'}\n",
        "\n",
        "    # Combine all styles\n",
        "    styles = [cell_hover, headers, column_separator, hide_last_border]\n",
        "    styled_df = styled_df.set_table_styles(styles, overwrite=False)\n",
        "\n",
        "    return styled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 111"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_path = './'\n",
        "report_filename = base_path + 'minimalEncoding_' +  str(seed) + '_' + str(65536) + '.txt'\n",
        "# report_filename = base_path + 'minimalEncoding_' +  str(seed) + '_' + str(32768) + '.txt'\n",
        "# report_filename = base_path + 'SampleTestMinimalEncoding_' +  str(seed) + '_' + str(8192) + '.txt'\n",
        "report_file_obj = open(report_filename,'r')\n",
        "table_contents = [line.replace('\\n','').split('__') for line in report_file_obj.readlines()]\n",
        "\n",
        "base_cols = ['No. of Pixels', 'Height', 'Width']\n",
        "sub_cols = ['','','']\n",
        "\n",
        "extra_sub_cols = ['Optimization Success','Result', 'TTE', 'Layers', 'Min-Cut Cost', 'Optimization Cost', 'Iterations', 'Optimizer Method']\n",
        "base_cols = base_cols+['Minimal Encoding Solver']*len(extra_sub_cols)\n",
        "sub_cols=sub_cols+extra_sub_cols\n",
        "\n",
        "column_arrays = [base_cols, sub_cols]\n",
        "\n",
        "#df = pd.DataFrame(table_contents, columns=table_headers)\n",
        "df = pd.DataFrame(table_contents, columns=pd.MultiIndex.from_arrays(column_arrays))\n",
        "\n",
        "for col in df.columns:\n",
        "  if len(col) == 2 and col[1] == 'Result':\n",
        "    df[col] = df[col].apply(lambda x: truncate_long_string(x))\n",
        "\n",
        "styled_df = style_df(df)#.apply(highlight_row, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "styled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert 'Minimal Encoding Solver' and 'Optimization Cost' columns to float\n",
        "df[['Minimal Encoding Solver', 'Optimization Cost']] = df[['Minimal Encoding Solver', 'Optimization Cost']].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def forest_segmentation(image_path, downsampling_factor = 64, edge_weight_metric = image_to_grid_graph, solver = minimal_encoding):\n",
        "  d = downsampling_factor\n",
        "\n",
        "  img = cv2.imread(image_path)\n",
        "  img = cv2.medianBlur(img, 31)\n",
        "  lower_green = np.array([35, 50, 50])\n",
        "  upper_green = np.array([90, 255, 255])\n",
        "  darkgreen_mask = cv2.inRange(cv2.cvtColor(img, cv2.COLOR_BGR2HSV), lower_green, upper_green)\n",
        "  darkgreen_mask = darkgreen_mask/255\n",
        "  darkgreen_mask[darkgreen_mask == 0] = -1\n",
        "\n",
        "\n",
        "  img = np.mean(img, axis = 2)/255\n",
        "  img = (1-img)*darkgreen_mask\n",
        "\n",
        "  height, width = img.shape\n",
        "  new_width = width // d\n",
        "  new_height = height // d\n",
        "  img = cv2.resize(img, [new_height,new_width])\n",
        "\n",
        "  pixel_values, elist, nx_elist, normalized_elist, normalized_nx_elist = edge_weight_metric(img)\n",
        "\n",
        "  G = nx.grid_2d_graph(img.shape[0], img.shape[1])\n",
        "  G.add_weighted_edges_from(normalized_nx_elist)\n",
        "\n",
        "  nc = len(G.nodes())\n",
        "  nr = ceil(log2(nc))\n",
        "  nq = nr + 1\n",
        "  np.random.seed(seed=initial_params_seed)\n",
        "  initial_params = np.random.uniform(low=-np.pi, high=np.pi, size=nq*n_layers)\n",
        "  print(f\"Executing QC with {n_layers} layers and {scipy_optimizer_method} optimizer for {height}*{height} image.\")\n",
        "  try:\n",
        "    start_time = time.time()\n",
        "    success_flag, minimal_encoding_solution, minimal_encoding_value, minimal_encoding_cut_value, optimal_params = minimal_encoding(G,\n",
        "                                                                                                                  initial_params,\n",
        "                                                                                                                  n_layers = 5,\n",
        "                                                                                                                  max_iter = optimization_max_iter,\n",
        "                                                                                                                  optimizer_method = 'COBYLA')\n",
        "    minimal_encoding_tte = (time.time() - start_time)\n",
        "  except:\n",
        "    print(f\"Execution Failed for {n_layers} layers and {scipy_optimizer_method} optimizer for {height}*{height} image.\")\n",
        "\n",
        "  output_mask = decode_binary_string(minimal_encoding_solution, img.shape[0], img.shape[1])\n",
        "  # print(output_mask)\n",
        "\n",
        "  mask = output_mask.repeat(d, axis=0).repeat(d, axis=1)\n",
        "  return mask, success_flag, minimal_encoding_solution, minimal_encoding_value, minimal_encoding_cut_value, optimal_params, minimal_encoding_tte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imgs_paths = [\"/content/Forest Segmented/Forest Segmented/images/111335_sat_00.jpg\",\n",
        "            \"/content/Forest Segmented/Forest Segmented/images/111335_sat_02.jpg\",\n",
        "            \"/content/Forest Segmented/Forest Segmented/images/10452_sat_18.jpg\",\n",
        "            \"/content/Forest Segmented/Forest Segmented/images/10452_sat_08.jpg\"]\n",
        "\n",
        "\n",
        "imgs_paths = [\"forest/10452_sat_08.jpg\"]\n",
        "\n",
        "for image_path in imgs_paths:\n",
        "  image = Image.open(image_path)\n",
        "  plt.imshow(np.asarray(image))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  mask, success_flag, minimal_encoding_solution, minimal_encoding_value, minimal_encoding_cut_value, optimal_params, minimal_encoding_tte = forest_segmentation(image_path)\n",
        "  plt.imshow(np.asarray(mask))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))  # Adjust the figure size as needed\n",
        "\n",
        "# First subplot for the first image\n",
        "plt.subplot(1, 2, 1)  # 1 row, 2 columns, first subplot\n",
        "plt.imshow(np.asarray(image))  # Adjust colormap as needed\n",
        "plt.axis('off')  # Hide the axis\n",
        "\n",
        "# Second subplot for the second image\n",
        "plt.subplot(1, 2, 2)  # 1 row, 2 columns, second subplot\n",
        "plt.imshow(np.asarray(mask), cmap='gray')  # Adjust colormap as needed\n",
        "plt.axis('off')  # Hide the axis\n",
        "\n",
        "# Display the figure with the two images\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))  # Adjust the figure size as needed\n",
        "\n",
        "# First subplot for the first image\n",
        "plt.subplot(1, 2, 1)  # 1 row, 2 columns, first subplot\n",
        "plt.imshow(np.asarray(image))  # Adjust colormap as needed\n",
        "plt.axis('off')  # Hide the axis\n",
        "\n",
        "# Second subplot for the second image\n",
        "plt.subplot(1, 2, 2)  # 1 row, 2 columns, second subplot\n",
        "plt.imshow(np.asarray(mask), cmap='gray')  # Adjust colormap as needed\n",
        "plt.axis('off')  # Hide the axis\n",
        "\n",
        "# Display the figure with the two images\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imgs_paths = [\"forest/111335_sat_00.jpg\"]\n",
        "\n",
        "for image_path in imgs_paths:\n",
        "  image = Image.open(image_path)\n",
        "  plt.imshow(np.asarray(image))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  mask, success_flag, minimal_encoding_solution, minimal_encoding_value, minimal_encoding_cut_value, optimal_params, minimal_encoding_tte = forest_segmentation(image_path)\n",
        "  plt.imshow(np.asarray(mask))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))  # Adjust the figure size as needed\n",
        "\n",
        "# First subplot for the first image\n",
        "plt.subplot(1, 2, 1)  # 1 row, 2 columns, first subplot\n",
        "plt.imshow(np.asarray(image))  # Adjust colormap as needed\n",
        "plt.axis('off')  # Hide the axis\n",
        "\n",
        "# Second subplot for the second image\n",
        "plt.subplot(1, 2, 2)  # 1 row, 2 columns, second subplot\n",
        "plt.imshow(np.asarray(mask), cmap='gray')  # Adjust colormap as needed\n",
        "plt.axis('off')  # Hide the axis\n",
        "\n",
        "# Display the figure with the two images\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imgs_paths = [\"forest/111335_sat_02.jpg\"]\n",
        "\n",
        "for image_path in imgs_paths:\n",
        "  image = Image.open(image_path)\n",
        "  plt.imshow(np.asarray(image))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  mask, success_flag, minimal_encoding_solution, minimal_encoding_value, minimal_encoding_cut_value, optimal_params, minimal_encoding_tte = forest_segmentation(image_path)\n",
        "  plt.imshow(np.asarray(mask))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))  # Adjust the figure size as needed\n",
        "\n",
        "# First subplot for the first image\n",
        "plt.subplot(1, 2, 1)  # 1 row, 2 columns, first subplot\n",
        "plt.imshow(np.asarray(image))  # Adjust colormap as needed\n",
        "plt.axis('off')  # Hide the axis\n",
        "\n",
        "# Second subplot for the second image\n",
        "plt.subplot(1, 2, 2)  # 1 row, 2 columns, second subplot\n",
        "plt.imshow(np.asarray(mask), cmap='gray')  # Adjust colormap as needed\n",
        "plt.axis('off')  # Hide the axis\n",
        "\n",
        "# Display the figure with the two images\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imgs_paths = [\"forest/10452_sat_18.jpg\"]\n",
        "\n",
        "for image_path in imgs_paths:\n",
        "  image = Image.open(image_path)\n",
        "  plt.imshow(np.asarray(image))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  mask, success_flag, minimal_encoding_solution, minimal_encoding_value, minimal_encoding_cut_value, optimal_params, minimal_encoding_tte = forest_segmentation(image_path)\n",
        "  plt.imshow(np.asarray(mask))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))  # Adjust the figure size as needed\n",
        "\n",
        "# First subplot for the first image\n",
        "plt.subplot(1, 2, 1)  # 1 row, 2 columns, first subplot\n",
        "plt.imshow(np.asarray(image))  # Adjust colormap as needed\n",
        "plt.axis('off')  # Hide the axis\n",
        "\n",
        "# Second subplot for the second image\n",
        "plt.subplot(1, 2, 2)  # 1 row, 2 columns, second subplot\n",
        "plt.imshow(np.asarray(mask), cmap='gray')  # Adjust colormap as needed\n",
        "plt.axis('off')  # Hide the axis\n",
        "\n",
        "# Display the figure with the two images\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1j3DrZFoaWG"
      },
      "source": [
        "#### Gurobi Solver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppNKAa3xoepG"
      },
      "outputs": [],
      "source": [
        "def gurobi_mincut_solver(G):\n",
        "  w = -1 * nx.adjacency_matrix(G).todense()\n",
        "  max_cut = Maxcut(w)\n",
        "  qp = max_cut.to_quadratic_program()\n",
        "  linear = qp.objective.linear.coefficients.toarray(order=None, out=None)\n",
        "  quadratic = qp.objective.quadratic.coefficients.toarray(order=None, out=None)\n",
        "\n",
        "  linear = {int(idx):-round(value,2) for idx,value in enumerate(linear[0])}\n",
        "  quadratic = {(int(iy),int(ix)):-quadratic[iy, ix] for iy, ix in np.ndindex(quadratic.shape) if iy<ix and abs(quadratic[iy, ix])!=0}\n",
        "\n",
        "  qubo_matrix = np.zeros([len(linear),len(linear)])\n",
        "  for key,value in linear.items():\n",
        "    qubo_matrix[int(key),int(key)] = value\n",
        "  for key,value in quadratic.items():\n",
        "    qubo_matrix[int(key[0]),int(key[1])] = value/2\n",
        "    qubo_matrix[int(key[1]),int(key[0])] = value/2\n",
        "\n",
        "  #size of the QUBO matrix\n",
        "  n = qubo_matrix.shape[0]\n",
        "  model = gp.Model()\n",
        "\n",
        "  #initialize binary variables\n",
        "  x = model.addVars(n, vtype=GRB.BINARY)\n",
        "\n",
        "  #objective function to minimize the QUBO matrix\n",
        "  obj_expr = gp.quicksum(qubo_matrix[i, j] * x[i] * x[j] for i in range(n) for j in range(n))\n",
        "  model.setObjective(obj_expr)\n",
        "\n",
        "  model.setParam('OutputFlag', 0)\n",
        "\n",
        "  model.optimize()\n",
        "\n",
        "  if model.status == GRB.OPTIMAL:\n",
        "    solution = [int(x[i].X) for i in range(n)]\n",
        "    binary_string = ''.join(str(bit) for bit in solution)\n",
        "    return binary_string, model.objVal\n",
        "  else:\n",
        "    return None, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP1_vNaufLJr"
      },
      "source": [
        "#### Choose the solvers for experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VJ1-Q3-1PgpZ"
      },
      "outputs": [],
      "source": [
        "#@title Choose the solvers for experiments\n",
        "brute_force_solver = False#@param {type:\"boolean\"}\n",
        "minimum_eigen_solver = False#@param {type:\"boolean\"}\n",
        "gurobi_solver = False#@param {type:\"boolean\"}\n",
        "qiskit_qaoa_solver = False#@param {type:\"boolean\"}\n",
        "new_nisq_solver = False#@param {type:\"boolean\"}\n",
        "minimal_encoding_solver = True#@param {type:\"boolean\"}\n",
        "dwave_annealer_solver = False#@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "solver_flags = ''.join(map(str,map(int,[brute_force_solver, minimum_eigen_solver, gurobi_solver, qiskit_qaoa_solver, new_nisq_solver, minimal_encoding_solver, dwave_annealer_solver])))\n",
        "solver_flags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Experimental Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhReie_Viuf1"
      },
      "outputs": [],
      "source": [
        "table_contents = []\n",
        "\n",
        "QAOA_reps = 1\n",
        "\n",
        "max_layers = 1000\n",
        "\n",
        "# heights = np.arange(2, 17).tolist()\n",
        "heights = [16,32]\n",
        "\n",
        "scipy_optimizer_methods = ['Nelder-Mead', 'Powell', 'CG', 'BFGS', 'L-BFGS-B', 'TNC', 'COBYLA', 'SLSQP', 'trust-constr']\n",
        "scipy_optimizer_methods = ['COBYLA']\n",
        "other_optimizer_methods = ['Genetic']\n",
        "\n",
        "seed = 111\n",
        "\n",
        "# base_path = '/content/drive/MyDrive/Saarland/QAI/newnisq_seg/'\n",
        "base_path = './'\n",
        "report_filename = base_path + 'minimalEncoding_seg_report_' + solver_flags + '_' +  str(seed) + '.txt'\n",
        "\n",
        "problem_instances = {}\n",
        "ultimate_valid_probabilities = []\n",
        "penultimate_valid_probabilities = []\n",
        "\n",
        "# np.random.seed(seed=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR_WVGyZQQIE"
      },
      "source": [
        "#### Executions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTuDZXgLXrsp",
        "outputId": "88e4f43f-60dd-437a-be6d-2a9542c31a87"
      },
      "outputs": [],
      "source": [
        "for height in heights:\n",
        "  # for width in widths:\n",
        "  width = height\n",
        "  print(f'height: {height}, width: {width}, n: {height*width}')\n",
        "  # G, image = generate_binary_problem_instance(height, width)\n",
        "  np.random.seed(seed=seed)\n",
        "  G, image = generate_problem_instance(height, width)\n",
        "  # print(\"Image Generated: \",image)\n",
        "  start_time = time.time()\n",
        "  if brute_force_solver:\n",
        "    brute_force_solution, brute_force_value = bf_solver(G)\n",
        "    print(\"BRUTE FORCE DONE!\")\n",
        "  else:\n",
        "    brute_force_solution, brute_force_value = None, None\n",
        "  brute_force_tte = (time.time() - start_time)\n",
        "\n",
        "  start_time = time.time()\n",
        "  if minimum_eigen_solver:\n",
        "    minimum_eigen_solution, minimum_eigen_value = me2_solver(G)\n",
        "    print(\"Minimum Eigensolver DONE!\")\n",
        "    # minimum_eigen_quality = get_quality(minimum_eigen_solution, brute_force_solution)\n",
        "  else:\n",
        "    minimum_eigen_solution, minimum_eigen_value = None, None\n",
        "    # minimum_eigen_quality = None\n",
        "  minimum_eigen_tte = (time.time() - start_time)\n",
        "\n",
        "  start_time = time.time()\n",
        "  if gurobi_solver:\n",
        "    gurobi_solution, gurobi_value = gurobi_mincut_solver(G)\n",
        "    print(\"Gurobi DONE!\")\n",
        "    # gurobi_quality = get_quality(gurobi_solution, brute_force_solution)\n",
        "  else:\n",
        "    gurobi_solution, gurobi_value = None, None\n",
        "    # gurobi_quality = None\n",
        "  gurobi_tte = (time.time() - start_time)\n",
        "\n",
        "  start_time = time.time()\n",
        "  if qiskit_qaoa_solver:\n",
        "    qiskit_qaoa_solution, qiskit_qaoa_value = qaoa_solver(G, QAOA_reps)\n",
        "    print(\"QAOA DONE!\")\n",
        "    # qiskit_qaoa_quality = get_quality(qiskit_qaoa_solution, brute_force_solution)\n",
        "  else:\n",
        "    qiskit_qaoa_solution, qiskit_qaoa_value = None, None\n",
        "    # qiskit_qaoa_quality = None\n",
        "  qiskit_qaoa_tte = (time.time() - start_time)\n",
        "  start_time = time.time()\n",
        "  if dwave_annealer_solver:\n",
        "    dwave_annealer_solution, dwave_annealer_value = annealer_solver(G)\n",
        "    print(\"ANNEALER DONE!\")\n",
        "    # dwave_annealer_quality = get_quality(dwave_annealer_solution, brute_force_solution)\n",
        "  else:\n",
        "    dwave_annealer_solution, dwave_annealer_value = None, None\n",
        "    # dwave_annealer_quality = None\n",
        "  dwave_annealer_tte = (time.time() - start_time)\n",
        "\n",
        "  # start_time = time.time()\n",
        "  # if new_nisq_genetic_solver:\n",
        "    # new_nisq_ga_solution, new_nisq_ga_expectation_value, new_nisq_ga_cut_value = new_nisq_ga_solver2(G, population_size = min(10,int(2*G.number_of_nodes())),\n",
        "                                                                                                      #  crossover_probability = 0.5,\n",
        "                                                                                                      #  mutation_probability = 0.5,\n",
        "                                                                                                      #  number_of_generations = min(10,int(2*G.number_of_nodes())))\n",
        "    # print(\"NEW NISQ GENETIC ALGORITHM DONE!\")\n",
        "  # else:\n",
        "    # new_nisq_ga_solution, new_nisq_ga_expectation_value, new_nisq_ga_cut_value = None, None, None\n",
        "  # new_nisq_ga_tte = (time.time() - start_time)\n",
        "\n",
        "  # initial_params = np.random.uniform(low=0.5, high=2*np.pi , size=(2**int(np.ceil(np.log2(int(G.number_of_nodes()))))))\n",
        "\n",
        "  # if G.number_of_nodes() < max_layers:\n",
        "    # max_layers = G.number_of_nodes()\n",
        "  # else:\n",
        "    # max_layers = 1000\n",
        "  for n_layers in range(400, max_layers+1,100):\n",
        "    nc = len(G.nodes())\n",
        "    nr = ceil(log2(nc))\n",
        "    nq = nr + 1\n",
        "    np.random.seed(seed=seed)\n",
        "    initial_params = np.random.uniform(low=-np.pi, high=np.pi, size=nq*n_layers)\n",
        "    for scipy_optimizer_method in scipy_optimizer_methods:\n",
        "      start_time = time.time()\n",
        "      if minimal_encoding_solver:\n",
        "        print(f\"Executing QC with {n_layers} layers and {scipy_optimizer_method} optimizer for {height}*{height} image.\")\n",
        "        minimal_encoding_solution, minimal_encoding_value, minimal_encoding_cut_value, optimal_params = minimal_encoding(G, \n",
        "                                                                                                                        initial_params, \n",
        "                                                                                                                        n_layers, \n",
        "                                                                                                                        optimizer_method = scipy_optimizer_method)\n",
        "        # minimal_encoding_solution, minimal_encoding_value, minimal_encoding_cut_value = new_nisq_algo_solver(G, scipy_optimizer_method, initial_params)\n",
        "        print(\"New NISQ done for\",scipy_optimizer_method,\"optimizer\")\n",
        "        # new_nisq_quality = get_quality(new_nisq_cut_value, brute_force_value)\n",
        "      else:\n",
        "        new_nisq_solution, new_nisq_expectation_value, new_nisq_cut_value = None, None, None\n",
        "        # new_nisq_quality = None\n",
        "      minimal_encoding_tte = (time.time() - start_time)\n",
        "      print(f\"Appending the results of {height}*{height} image using QC with {n_layers} layers and {scipy_optimizer_method} optimizer.\")\n",
        "      row = []\n",
        "      row.append(int(G.number_of_nodes()))\n",
        "      row.append(int(height))\n",
        "      row.append(int(width))\n",
        "      if brute_force_solver:\n",
        "        row.append(''.join(map(str, map(int, (brute_force_solution)))))\n",
        "        row.append(brute_force_value)\n",
        "        row.append(np.round(brute_force_tte,6))\n",
        "      if minimum_eigen_solver:\n",
        "        row.append(''.join(map(str, map(int, (minimum_eigen_solution)))))\n",
        "        row.append(minimum_eigen_value)\n",
        "        row.append(np.round(minimum_eigen_tte,6))\n",
        "        # row.append(minimum_eigen_quality)\n",
        "      if gurobi_solver:\n",
        "        row.append(''.join(map(str, map(int, (gurobi_solution)))))\n",
        "        row.append(gurobi_value)\n",
        "        row.append(np.round(gurobi_tte,6))\n",
        "        # row.append(minimum_eigen_quality)\n",
        "      if qiskit_qaoa_solver:\n",
        "        row.append(''.join(map(str, map(int, (qiskit_qaoa_solution)))))\n",
        "        row.append(qiskit_qaoa_value)\n",
        "        row.append(np.round(qiskit_qaoa_tte,6))\n",
        "        # row.append(qiskit_qaoa_quality)\n",
        "        row.append(QAOA_reps)\n",
        "      if dwave_annealer_solver:\n",
        "        row.append(''.join(map(str, map(int, (dwave_annealer_solution)))))\n",
        "        row.append(dwave_annealer_value)\n",
        "        row.append(np.round(dwave_annealer_tte,6))\n",
        "        # row.append(dwave_annealer_quality)\n",
        "      # if new_nisq_genetic_solver:\n",
        "        # row.append(''.join(map(str, map(int, (new_nisq_ga_solution)))))\n",
        "        # row.append(new_nisq_ga_cut_value)\n",
        "        # row.append(np.round(new_nisq_ga_tte,6))\n",
        "        # # row.append(new_nisq_ga_quality)\n",
        "        # row.append(new_nisq_ga_expectation_value)\n",
        "      if new_nisq_solver:\n",
        "        row.append(''.join(map(str, map(int, (new_nisq_solution)))))\n",
        "        row.append(new_nisq_cut_value)\n",
        "        row.append(np.round(new_nisq_tte,6))\n",
        "        # row.append(new_nisq_quality)\n",
        "        row.append(new_nisq_expectation_value)\n",
        "        row.append(scipy_optimizer_method)\n",
        "      if minimal_encoding_solver:\n",
        "        row.append(''.join(map(str, map(int, (minimal_encoding_solution)))))\n",
        "        row.append(minimal_encoding_cut_value)\n",
        "        row.append(np.round(minimal_encoding_tte,6))\n",
        "        row.append(n_layers)\n",
        "        row.append(minimal_encoding_value)\n",
        "        row.append(scipy_optimizer_method)\n",
        "        # row.append(''.join(map(str, map(float, (optimal_params)))))\n",
        "      report_file_obj = open(os.path.join(report_filename),'a+')\n",
        "      report_file_obj.write('__'.join(map(str,row))+'\\n')\n",
        "      report_file_obj.close()\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smXhk33Afk9L"
      },
      "source": [
        "#### Display report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QghfP-IcOrUY"
      },
      "outputs": [],
      "source": [
        "def decode_binary_string(x, height, width):\n",
        "  mask = np.zeros([height, width])\n",
        "  for index,segment in enumerate(x):\n",
        "    mask[index//width,index%width]=segment\n",
        "  return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wKXK3hctXuMa",
        "outputId": "74bb8723-7b40-4cc5-ae86-75dfac7164ff"
      },
      "outputs": [],
      "source": [
        "base_path = '/content/drive/MyDrive/Saarland/QAI/newnisq_seg/'\n",
        "base_path = './'\n",
        "\n",
        "\n",
        "report_filename = base_path + 'minimalEncoding_seg_report_' + solver_flags + '_' +  str(seed) + '.txt'\n",
        "report_filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiDA0fccXuFW"
      },
      "outputs": [],
      "source": [
        "brute_force_solver = bool(int(report_filename.split('_')[-2][0]))\n",
        "minimum_eigen_solver = bool(int(report_filename.split('_')[-2][1]))\n",
        "gurobi_solver = bool(int(report_filename.split('_')[-2][2]))\n",
        "qiskit_qaoa_solver = bool(int(report_filename.split('_')[-2][3]))\n",
        "dwave_annealer_solver = bool(int(report_filename.split('_')[-2][4]))\n",
        "new_nisq_solver = bool(int(report_filename.split('_')[-2][5]))\n",
        "\n",
        "report_file_obj = open(os.path.join(report_filename),'r')\n",
        "table_contents = [line.replace('\\n','').split('__') for line in report_file_obj.readlines()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvnCn5qeA3GD",
        "outputId": "03d8201e-1327-49e8-bcd0-a8f0218022a9"
      },
      "outputs": [],
      "source": [
        "print(brute_force_solver)\n",
        "print(minimum_eigen_solver)\n",
        "print(gurobi_solver)\n",
        "print(qiskit_qaoa_solver)\n",
        "print(dwave_annealer_solver)\n",
        "print(new_nisq_solver)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFnYmms_lSep"
      },
      "outputs": [],
      "source": [
        "bf_solver_name = 'Brute Force (Exact)'\n",
        "me_solver_name = 'Minimum Eigen (Classical)'\n",
        "gurobi_solver_name = 'Gurobi (Classical SotA)'\n",
        "qaoa_solver_name = 'Qiskit QAOA'\n",
        "annealer_solver_name = 'D-Wave 2000Q'\n",
        "new_nisq_solver_name = 'New NISQ Algorithm'\n",
        "\n",
        "base_cols = ['No. of Pixels', 'Height', 'Width']\n",
        "sub_cols = ['','','']\n",
        "\n",
        "if brute_force_solver:\n",
        "  base_cols = base_cols+[bf_solver_name]*3\n",
        "  sub_cols=sub_cols+['Result', 'Value', 'TTE']\n",
        "if minimum_eigen_solver:\n",
        "  base_cols = base_cols+[me_solver_name]*3\n",
        "  sub_cols=sub_cols+['Result', 'Value', 'TTE']\n",
        "if gurobi_solver:\n",
        "  base_cols = base_cols+[gurobi_solver_name]*3\n",
        "  sub_cols=sub_cols+['Result', 'Value', 'TTE']\n",
        "if qiskit_qaoa_solver:\n",
        "  base_cols = base_cols+[qaoa_solver_name]*4\n",
        "  sub_cols=sub_cols+['Result', 'Value', 'TTE', 'QAOA layers (p)']\n",
        "if dwave_annealer_solver:\n",
        "  base_cols = base_cols+[annealer_solver_name]*3\n",
        "  sub_cols=sub_cols+['Result', 'Value', 'TTE']\n",
        "if new_nisq_solver:\n",
        "  base_cols = base_cols+[new_nisq_solver_name]*6\n",
        "  sub_cols=sub_cols+['Result', 'Value', 'TTE', 'Layers', 'Expectation Value', 'Optimizer Method']\n",
        "\n",
        "column_arrays = [base_cols, sub_cols]\n",
        "\n",
        "\n",
        "#df = pd.DataFrame(table_contents, columns=table_headers)\n",
        "df = pd.DataFrame(table_contents, columns=pd.MultiIndex.from_arrays(column_arrays))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for row in range(len(df)):\n",
        "    print(df[('New NISQ Algorithm','Result')][row])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqip0nARvW6j"
      },
      "outputs": [],
      "source": [
        "def truncate_long_string(s, max_length=20):\n",
        "    return s if len(s) <= max_length else s[:max_length] + \"...\"\n",
        "\n",
        "# Apply this function to the specific column(s)\n",
        "for col in df.columns:\n",
        "  if len(col) == 2 and col[1] == 'Result':\n",
        "    df[col] = df[col].apply(lambda x: truncate_long_string(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIc8ch_Sws6i"
      },
      "outputs": [],
      "source": [
        "# def highlight_row(s):\n",
        "#     should_highlight = abs(round(float(s[(new_nisq_solver_name, 'Value')]), 3)) == abs(round(float(s[(gurobi_solver_name, 'Value')]), 3))\n",
        "#     return ['background-color: #606f60' if should_highlight else '' for _ in s]\n",
        "\n",
        "# df = df.apply(highlight_row, axis=1)\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vMqdzs2-mC8k",
        "outputId": "6b1e488b-f19b-473f-8a19-30e2d20dce51"
      },
      "outputs": [],
      "source": [
        "def style_df(df):\n",
        "    # Styles for hover and headers\n",
        "    cell_hover = {'selector': 'tr:hover', 'props': [('background-color', '#707070')]}  # Dark pale color for hover\n",
        "    headers = {'selector': 'th', 'props': 'background-color: #1D1D1D; color: white;'}\n",
        "\n",
        "    # Column separator style\n",
        "    column_separator = {'selector': 'td, th', 'props': 'border-right: 1px solid white;'}\n",
        "\n",
        "    # Apply the styles\n",
        "    styled_df = df.style.set_table_styles([cell_hover, headers, column_separator])\n",
        "\n",
        "    # Style to hide the border for the last column to prevent a double line at the end of the table\n",
        "    hide_last_border = {'selector': 'td:last-child, th:last-child', 'props': 'border-right: none;'}\n",
        "\n",
        "    # Combine all styles\n",
        "    styles = [cell_hover, headers, column_separator, hide_last_border]\n",
        "    styled_df = styled_df.set_table_styles(styles, overwrite=False)\n",
        "\n",
        "    return styled_df\n",
        "\n",
        "styled_df = style_df(df)#.apply(highlight_row, axis=1)\n",
        "\n",
        "styled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6Tlf-2ZlspA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "etaCXXCaEX1h",
        "FIIH27AZERXD",
        "-qstUcHjD16P",
        "9oXP6la6icxT",
        "2pPiM0ePig7A",
        "pePrU6XBikMV",
        "pAyb7qZ3iqzN",
        "X7JccFLY8tnr",
        "oNJMb9PMiu1S",
        "o1j3DrZFoaWG",
        "3TY83OitQNIm",
        "eR_WVGyZQQIE",
        "smXhk33Afk9L",
        "oCiGtxaIDp15"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
